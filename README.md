# Projet LinkedIn Data Pipeline & Dashboard

Ce dÃ©pÃ´t prÃ©sente la mise en place d'une pipeline ETL avec Snowflake et d'un dashboard interactif avec Streamlit, Ã  partir de donnÃ©es d'offres d'emploi LinkedIn.

---

## ğŸ“‚ Structure du dÃ©pÃ´t

```text
linkedin-project/
â”‚
â”œâ”€â”€ README.md                  # Ce document
â”œâ”€â”€ sql/                       # Scripts SQL commentÃ©s par Ã©tape
â”‚   â”œâ”€â”€ 01_create_schema.sql
â”‚   â”œâ”€â”€ 02_file_formats_and_stage.sql
â”‚   â”œâ”€â”€ 03_raw_tables.sql
â”‚   â”œâ”€â”€ 04_load_raw_data.sql
â”‚   â”œâ”€â”€ 05_json_ingestion.sql
â”‚   â”œâ”€â”€ 06_transform_to_clean.sql
â”‚   â””â”€â”€ 07_industries_dimension.sql
â”‚
â”œâ”€â”€ streamlit/                 # Application Streamlit et visuels
â”‚   â”œâ”€â”€ app.py                 # Code principal

â”œâ”€â”€ docs/                      # Documentation des problÃ¨mes et notes
â”‚   â”œâ”€â”€ PROBLEMS_AND_SOLUTIONS.md
â”‚   â””â”€â”€ NOTES_ON_IMPLEMENTATION.md
â”‚
â””â”€â”€ .gitignore                 # Fichiers et dossiers ignorÃ©s par Git
```

---

## ğŸ”§ Installation et exÃ©cution

1. **Cloner le dÃ©pÃ´t**


2. **ExÃ©cuter les scripts SQL dans Snowflake**

   * Charger, dans l'ordre, les fichiers du dossier `sql/` :

     1. `01_create_schema.sql`
     2. `02_file_formats_and_stage.sql`
     3. `03_raw_tables.sql`
     4. `04_load_raw_data.sql`
     5. `05_json_ingestion.sql`
     6. `06_transform_to_clean.sql`
     7. `07_industries_dimension.sql`

3. **Lancer l'application Streamlit**


## ğŸ—‚ï¸ Scripts SQL dÃ©taillÃ©s

Chaque script se trouve dans `sql/` et comprend :

* **Commentaires** explicatifs (`-- === COMMENTAIRE ===`).
* **Ã‰tapes** successives de la pipeline (crÃ©ation de la base, formats, tables raw, chargement, JSON VARIANT, nettoyage, dimensions).

**Points clÃ©s** :

* Utilisation dâ€™un **stage S3** pour charger CSV et JSON.
* Formats personnalisÃ©s pour CSV (`SKIP_HEADER`, `PARSE_HEADER`, `ERROR_ON_COLUMN_COUNT_MISMATCH`).
* Tables **raw** vs tables **propres** : on ingÃ¨re dâ€™abord en brut, puis on transforme via `LATERAL FLATTEN`.
* Table de dimension `industries` pour rapprocher les `industry_id` de leur libellÃ©.

---

## ğŸ“Š Application Streamlit

Le fichier `streamlit/app.py` contient :

1. **Distribution des salaires**

   * Histogramme filtrable avec `st.slider`.
2. **Nombre d'offres par industrie**

   * Histogramme interactif.
3. **Top 10 des entreprises**

   * Tableau triable et filtrable.

Chaque section est commentÃ©e (`# === COMMENTAIRE ===`) pour expliquer la logique et les widgets Streamlit utilisÃ©s.

---

## âš ï¸ ProblÃ¨mes rencontrÃ©s & solutions

| ProblÃ¨me                                                                                  | Cause identifiÃ©e                                                                | Solution appliquÃ©e                                                                                                                                       |
| ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Parsing JSON malformÃ©**                                                                 | Certains fichiers JSON contenaient des lignes incorrectes                       | Ajout de `ON_ERROR = 'CONTINUE'` dans les commandes `COPY` pour avancer malgrÃ© les erreurs, suivi d'une inspection manuelle des lignes corrompues.       |
| **IncohÃ©rence entre colonnes CSV et table**                                               | Noms de colonnes CSV ne correspondaient pas toujours (casse, espaces)           | Utilisation de `MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE` et `PARSE_HEADER = TRUE` pour la correspondance automatique des noms de colonnes.               |
| **KPIs par secteurÂ : affichage des *IDs* au lieu des *noms***                             | Oubli de jointure entre la table factuelle des offres et la table `industries`. | Ajout dâ€™une requÃªte SQL avec `JOIN industries USING(industry_id)` pour remplacer les `industry_id` par `industry_name` avant gÃ©nÃ©ration des KPI/graphes. |
| **Taille des donnÃ©es**â€¯: lenteur Ã  lâ€™affichage des graphiques Streamlit pour gros volumes | Chargement complet en mÃ©moire, pas de pagination                                | ImplÃ©mentation dâ€™un **Ã©chantillonnage** (`df.sample(0.3)`) et/ou dâ€™une **pagination** via `st.dataframe(..., height=..)`.                                |

---

## ğŸ“– Notes d'implÃ©mentation

Voir `docs/NOTES_ON_IMPLEMENTATION.md` pour :

* Contexte et **choix d'architecture** (Snowflake + Streamlit).
* Bonnes pratiques suivies (naming conventions, modularitÃ© des scripts, utilisation de `LATERAL FLATTEN`).
* **SÃ©curitÃ©** et accÃ¨s (gestion des credentials Snowflake via variables d'environnement).

---

## ğŸš€ KPIs & Visualisations


1. Top 10 des titres de postes les plus publiÃ©s par industrie.

2. Top 10 des postes les mieux rÃ©munÃ©rÃ©s par industrie.

3. RÃ©partition des offres dâ€™emploi par taille dâ€™entreprise.

4. RÃ©partition des offres dâ€™emploi par secteur dâ€™activitÃ©.

5. RÃ©partition des offres dâ€™emploi par type dâ€™emploi (temps plein, stage, temps partiel).

**Note** : la jointure avec la dimension `industries` doit Ãªtre effectuÃ©e pour afficher les libellÃ©s au lieu des IDs.

---


